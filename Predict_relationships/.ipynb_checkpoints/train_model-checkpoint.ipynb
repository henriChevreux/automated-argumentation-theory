{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a63356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 14:27:56.566736: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/henrichevreux/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0815d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 50, 100)              488500    ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, 50, 100)              488500    ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, 50, 32)               17024     ['embedding_6[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, 50, 32)               17024     ['embedding_7[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 50, 64)               0         ['lstm_6[0][0]',              \n",
      " )                                                                   'lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 3200)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 32)                   102432    ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 3)                    99        ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1113579 (4.25 MB)\n",
      "Trainable params: 136579 (533.51 KB)\n",
      "Non-trainable params: 977000 (3.73 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "new_model = tf.keras.models.load_model('saved_models/relationshipBuilder_model')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30914603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If anyone seriously thinks that UKIP will offe...</td>\n",
       "      <td>He claimed the document was nothing more a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reason why UKIP has gained so many votes i...</td>\n",
       "      <td>If I was confident that Labour were going to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UKIP are not rabid racist and not another inca...</td>\n",
       "      <td>He also suggested that his party might get its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with popularism but no substance, ...</td>\n",
       "      <td>It is fielding 1,217 candidates this time - a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyond leaving the EU and migration what ukip ...</td>\n",
       "      <td>Mr Hamilton will sit on UKIP's national execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Despite their best efforts at pretending other...</td>\n",
       "      <td>He made the comment during a debate on EU prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>The problem with popularism but no substance, ...</td>\n",
       "      <td>Conservative party vice chairman Michael Fabri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>If the other parties do tackle the issues of E...</td>\n",
       "      <td>Timo Soini, leader of the Eurosceptic True Fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>Even a UKIP European candidate, Janice Atkinso...</td>\n",
       "      <td>Speaking on The World At One Nigel Farage, lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>If you think that the Tories are nasty, heaven...</td>\n",
       "      <td>The penny is beginning to drop with the Britis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2274 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     If anyone seriously thinks that UKIP will offe...   \n",
       "1     The reason why UKIP has gained so many votes i...   \n",
       "2     UKIP are not rabid racist and not another inca...   \n",
       "3     The problem with popularism but no substance, ...   \n",
       "4     Beyond leaving the EU and migration what ukip ...   \n",
       "...                                                 ...   \n",
       "2269  Despite their best efforts at pretending other...   \n",
       "2270  The problem with popularism but no substance, ...   \n",
       "2271  If the other parties do tackle the issues of E...   \n",
       "2272  Even a UKIP European candidate, Janice Atkinso...   \n",
       "2273  If you think that the Tories are nasty, heaven...   \n",
       "\n",
       "                                                      1  \n",
       "0     He claimed the document was nothing more a col...  \n",
       "1     If I was confident that Labour were going to d...  \n",
       "2     He also suggested that his party might get its...  \n",
       "3     It is fielding 1,217 candidates this time - a ...  \n",
       "4     Mr Hamilton will sit on UKIP's national execut...  \n",
       "...                                                 ...  \n",
       "2269  He made the comment during a debate on EU prop...  \n",
       "2270  Conservative party vice chairman Michael Fabri...  \n",
       "2271  Timo Soini, leader of the Eurosceptic True Fin...  \n",
       "2272  Speaking on The World At One Nigel Farage, lea...  \n",
       "2273  The penny is beginning to drop with the Britis...  \n",
       "\n",
       "[2274 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2274 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     n\n",
       "1     n\n",
       "2     s\n",
       "3     n\n",
       "4     n\n",
       "...  ..\n",
       "2269  n\n",
       "2270  n\n",
       "2271  n\n",
       "2272  a\n",
       "2273  a\n",
       "\n",
       "[2274 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import UKIP dataset\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_excel(r\"../../datasets/UKIP.xlsx\", sheet_name=\"Feuil1\", header=None)\n",
    "\n",
    "df = shuffle(df).reset_index(drop=True)\n",
    "\n",
    "# Split features and labels\n",
    "X = df[[3, 4]].T.reset_index(drop=True).T\n",
    "y = df[[5]].T.reset_index(drop=True).T\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d686ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1591, 2)\n",
      "[\"In contrast, the Liberal Democrat's Bill Newton Dunn quit the Tories in protest at its increasing hostility to Europe. And now?\"\n",
      " 'The group suggest that within five years UKIP will have more members than the Tories at the current rate of attrition.'\n",
      " 'Afterwards, Mr Nattrass began discussions with the English Democrats, who campaign for the establishment of an English parliament and immediate withdrawal from the EU, about a possible move.'\n",
      " ...\n",
      " 'I think of the volunteers in my own constituency, they are not just my friends and my supporters, I feel I am one of them.'\n",
      " 'In fact, Downing Street have already briefed that David Cameron was actually too busy running the country he said.'\n",
      " 'Farage told the BBC the Conservatives were virtually indistinguishable from Labour and the Lib Dems on many issues and that UKIP was offering a real alternative.'] (1591,)\n"
     ]
    }
   ],
   "source": [
    "# Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split pairs of sentences\n",
    "sentences_train_1 = X_train[0].to_numpy()\n",
    "sentences_train_2 = X_train[1].to_numpy()\n",
    "\n",
    "sentences_test_1 = X_test[0].to_numpy()\n",
    "sentences_test_2 = X_test[1].to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424b751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]] [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# prepare target\n",
    "le = LabelEncoder()\n",
    "le.fit(np.ravel(y))\n",
    "y_train_enc = le.transform(np.ravel(y_train))\n",
    "y_test_enc = le.transform(np.ravel(y_test))\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train_enc = to_categorical(y_train_enc)\n",
    "y_test_enc = to_categorical(y_test_enc)\n",
    "\n",
    "print(y_train_enc, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f49c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If anyone seriously thinks that UKIP will offer some kind of answer to our current problems then I think that they are going to be sadly disappointed.'\n",
      " 'The reason why UKIP has gained so many votes is because the main parties refuse to deal with immigration and the EU.'\n",
      " 'UKIP are not rabid racist and not another incarnation of the BNP.' ...\n",
      " \"Timo Soini, leader of the Eurosceptic True Finns Party, which gained 19% of the vote at Finland's general election in April, will also address delegates.\"\n",
      " 'Speaking on The World At One Nigel Farage, leader of the UKIP party, told presenter Shaun Ley that he believes that UKIP are offering a real alternative, and leaving the EU is at the heart of it.'\n",
      " 'The penny is beginning to drop with the British people and British businesses that we are no longer a self-governing nation, and UKIP are here to remedy this.']\n",
      "50\n",
      "(683, 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten features for Glove fitting\n",
    "texts = np.concatenate([X[0], X[1]])\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "# Encode training data\n",
    "sequences_train_1 = tokenizer.texts_to_sequences(sentences_train_1)\n",
    "sequences_train_2 = tokenizer.texts_to_sequences(sentences_train_2)\n",
    "\n",
    "# Encode testing data\n",
    "sequences_test_1 = tokenizer.texts_to_sequences(sentences_test_1)\n",
    "sequences_test_2 = tokenizer.texts_to_sequences(sentences_test_2)\n",
    "\n",
    "# Padding sequences to have the same length\n",
    "max_len = 50\n",
    "print(max_len)\n",
    "padded_sequences_train_1 = pad_sequences(sequences_train_1, maxlen=max_len, padding='post')\n",
    "padded_sequences_train_2 = pad_sequences(sequences_train_2, maxlen=max_len, padding='post')\n",
    "\n",
    "padded_sequences_test_1 = pad_sequences(sequences_test_1, maxlen=max_len, padding='post')\n",
    "padded_sequences_test_2 = pad_sequences(sequences_test_2, maxlen=max_len, padding='post')\n",
    "\n",
    "print(np.shape(padded_sequences_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a94e8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "# Load pre-trained GloVe embeddings (you need to download the GloVe file)\n",
    "glove_embeddings_index = {}\n",
    "with open('glove/glove.6B.100d.txt', encoding='utf-8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix using GloVe for words in our tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c9f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1286 - accuracy: 0.7511\n",
      "test loss, test acc: [0.12855786085128784, 0.751098096370697]\n"
     ]
    }
   ],
   "source": [
    "results = new_model.evaluate([padded_sequences_test_1, padded_sequences_test_2], y_test_enc, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eadf425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "test = new_model.predict([padded_sequences_test_1, padded_sequences_test_2])\n",
    "\n",
    "label_map = {\n",
    "    '1': 'n',\n",
    "    '0': 'a',\n",
    "    '2': 's',\n",
    "}\n",
    "\n",
    "for t in range(len(test)):\n",
    "    arg = str(np.argmax(test[t]))\n",
    "    arg_dec = label_map.get(arg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_data = df[[3, 4, 5]].T.reset_index(drop=True).T\n",
    "#export_data.to_csv('UKIP_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3493c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
