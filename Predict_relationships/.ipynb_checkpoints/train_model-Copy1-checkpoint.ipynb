{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a63356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 15:40:14.409495: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/henrichevreux/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0815d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 50, 100)              488500    ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, 50, 100)              488500    ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, 50, 32)               17024     ['embedding_6[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, 50, 32)               17024     ['embedding_7[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 50, 64)               0         ['lstm_6[0][0]',              \n",
      " )                                                                   'lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 3200)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 32)                   102432    ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 3)                    99        ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1113579 (4.25 MB)\n",
      "Trainable params: 136579 (533.51 KB)\n",
      "Non-trainable params: 977000 (3.73 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "new_model = tf.keras.models.load_model('saved_models/relationshipBuilder_model')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30914603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carbon  is not the only method of dating used ...</td>\n",
       "      <td>to the  currently   voting   yes that raises s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we also investigate axis of evil aoe type anom...</td>\n",
       "      <td>while i am quite happy with pwning  of the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>being an atheist in a catholic school i can t...</td>\n",
       "      <td>you have to consider the alternative explanat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whats a darwinist can someone who says that th...</td>\n",
       "      <td>luskin quotesmay not the principle of uniformi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>should visited and joined be the same</td>\n",
       "      <td>no joined is the date a user registered to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>Only an idiot would think a UKIP win would res...</td>\n",
       "      <td>Clearly I would have preferred to get more vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>If UKIP is really the best our country can do ...</td>\n",
       "      <td>UKIP better represents the views of Conservati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>The country faces more than two big issues, wh...</td>\n",
       "      <td>UKIP MEP candidate Diane James, who came close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>I suspect when people do start to focus and th...</td>\n",
       "      <td>Labour has declined to say how it expects to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>UKIP are a fairly right wing group as I'm sure...</td>\n",
       "      <td>He pointed to the example of Norway, which has...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     carbon  is not the only method of dating used ...   \n",
       "1     we also investigate axis of evil aoe type anom...   \n",
       "2      being an atheist in a catholic school i can t...   \n",
       "3     whats a darwinist can someone who says that th...   \n",
       "4                 should visited and joined be the same   \n",
       "...                                                 ...   \n",
       "4053  Only an idiot would think a UKIP win would res...   \n",
       "4054  If UKIP is really the best our country can do ...   \n",
       "4055  The country faces more than two big issues, wh...   \n",
       "4056  I suspect when people do start to focus and th...   \n",
       "4057  UKIP are a fairly right wing group as I'm sure...   \n",
       "\n",
       "                                                      1  \n",
       "0     to the  currently   voting   yes that raises s...  \n",
       "1     while i am quite happy with pwning  of the thr...  \n",
       "2      you have to consider the alternative explanat...  \n",
       "3     luskin quotesmay not the principle of uniformi...  \n",
       "4     no joined is the date a user registered to the...  \n",
       "...                                                 ...  \n",
       "4053  Clearly I would have preferred to get more vot...  \n",
       "4054  UKIP better represents the views of Conservati...  \n",
       "4055  UKIP MEP candidate Diane James, who came close...  \n",
       "4056  Labour has declined to say how it expects to d...  \n",
       "4057  He pointed to the example of Norway, which has...  \n",
       "\n",
       "[4058 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4058 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     s\n",
       "1     s\n",
       "2     s\n",
       "3     s\n",
       "4     a\n",
       "...  ..\n",
       "4053  n\n",
       "4054  a\n",
       "4055  n\n",
       "4056  n\n",
       "4057  n\n",
       "\n",
       "[4058 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import UKIP dataset\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_excel(r\"../../datasets/ACMToIT2017_dataset.xlsx\", sheet_name=\"Sheet1\", header=None)\n",
    "\n",
    "df = shuffle(df).reset_index(drop=True)\n",
    "\n",
    "# Split features and labels\n",
    "X = df[[3, 4]].T.reset_index(drop=True).T\n",
    "y = df[[5]].T.reset_index(drop=True).T\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d686ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split pairs of sentences\n",
    "sentences_train_1 = X_train[0].to_numpy()\n",
    "sentences_train_2 = X_train[1].to_numpy()\n",
    "\n",
    "sentences_test_1 = X_test[0].to_numpy()\n",
    "sentences_test_2 = X_test[1].to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424b751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]] [[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# prepare target\n",
    "le = LabelEncoder()\n",
    "le.fit(np.ravel(y))\n",
    "y_train_enc = le.transform(np.ravel(y_train))\n",
    "y_test_enc = le.transform(np.ravel(y_test))\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train_enc = to_categorical(y_train_enc)\n",
    "y_test_enc = to_categorical(y_test_enc)\n",
    "\n",
    "print(y_train_enc, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f49c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "(1218, 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten features for Glove fitting\n",
    "texts = np.concatenate([X[0], X[1]])\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "# Encode training data\n",
    "sequences_train_1 = tokenizer.texts_to_sequences(sentences_train_1)\n",
    "sequences_train_2 = tokenizer.texts_to_sequences(sentences_train_2)\n",
    "\n",
    "# Encode testing data\n",
    "sequences_test_1 = tokenizer.texts_to_sequences(sentences_test_1)\n",
    "sequences_test_2 = tokenizer.texts_to_sequences(sentences_test_2)\n",
    "\n",
    "# Padding sequences to have the same length\n",
    "max_len = 50\n",
    "print(max_len)\n",
    "padded_sequences_train_1 = pad_sequences(sequences_train_1, maxlen=max_len, padding='post')\n",
    "padded_sequences_train_2 = pad_sequences(sequences_train_2, maxlen=max_len, padding='post')\n",
    "\n",
    "padded_sequences_test_1 = pad_sequences(sequences_test_1, maxlen=max_len, padding='post')\n",
    "padded_sequences_test_2 = pad_sequences(sequences_test_2, maxlen=max_len, padding='post')\n",
    "\n",
    "print(np.shape(padded_sequences_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94e8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "# Load pre-trained GloVe embeddings (you need to download the GloVe file)\n",
    "glove_embeddings_index = {}\n",
    "with open('glove/glove.6B.100d.txt', encoding='utf-8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix using GloVe for words in our tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c9f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1286 - accuracy: 0.7511\n",
      "test loss, test acc: [0.12855786085128784, 0.751098096370697]\n"
     ]
    }
   ],
   "source": [
    "results = new_model.evaluate([padded_sequences_test_1, padded_sequences_test_2], y_test_enc, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf425b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c9a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3493c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
