{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a63356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, concatenate, Dense, Flatten, Embedding, Bidirectional, Dropout, GlobalMaxPooling1D, BatchNormalization, SpatialDropout1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30914603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>relationship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Nancy’s skipping over Sean\"</td>\n",
       "      <td>\"Sean wants Nancy to bring the problems to him...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Sean does not know what’s bothering Nancy if ...</td>\n",
       "      <td>\"what Sean and Nancy could do is Sean sets the...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Sean can’t read minds\"</td>\n",
       "      <td>\"Sean does not know what’s bothering Nancy if ...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Sean doesn’t want to feel like Nancy and Sean...</td>\n",
       "      <td>\"what Sean and Nancy could do is Sean sets the...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Sean doesn't want to get all heated up and an...</td>\n",
       "      <td>\"Nancy and Sean should have a drink together\"</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35899</th>\n",
       "      <td>35899</td>\n",
       "      <td>\"says Oregon’s law has the potential to be “ab...</td>\n",
       "      <td>\"In essence, it seems as though the central cl...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35900</th>\n",
       "      <td>35900</td>\n",
       "      <td>\"And why do you suppose they aren't? Could it ...</td>\n",
       "      <td>\"My goal is to reach the people\"</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35901</th>\n",
       "      <td>35901</td>\n",
       "      <td>\"lol...you read my whole post only to conclude...</td>\n",
       "      <td>\"In general, I think that blanket policies on ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35902</th>\n",
       "      <td>35902</td>\n",
       "      <td>\"No. you're not making any sense. Where is sym...</td>\n",
       "      <td>\"Japanese ISPs To Ban FileSharers\"</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35903</th>\n",
       "      <td>35903</td>\n",
       "      <td>\"Admin: We want to be as productive as possible\"</td>\n",
       "      <td>\"We should listen to the women and empower them\"</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35904 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          argument1  \\\n",
       "0               0                       \"Nancy’s skipping over Sean\"   \n",
       "1               1  \"Sean does not know what’s bothering Nancy if ...   \n",
       "2               2                            \"Sean can’t read minds\"   \n",
       "3               3  \"Sean doesn’t want to feel like Nancy and Sean...   \n",
       "4               4  \"Sean doesn't want to get all heated up and an...   \n",
       "...           ...                                                ...   \n",
       "35899       35899  \"says Oregon’s law has the potential to be “ab...   \n",
       "35900       35900  \"And why do you suppose they aren't? Could it ...   \n",
       "35901       35901  \"lol...you read my whole post only to conclude...   \n",
       "35902       35902  \"No. you're not making any sense. Where is sym...   \n",
       "35903       35903   \"Admin: We want to be as productive as possible\"   \n",
       "\n",
       "                                               argument2 relationship  \n",
       "0      \"Sean wants Nancy to bring the problems to him...            s  \n",
       "1      \"what Sean and Nancy could do is Sean sets the...            s  \n",
       "2      \"Sean does not know what’s bothering Nancy if ...            s  \n",
       "3      \"what Sean and Nancy could do is Sean sets the...            a  \n",
       "4          \"Nancy and Sean should have a drink together\"            s  \n",
       "...                                                  ...          ...  \n",
       "35899  \"In essence, it seems as though the central cl...            n  \n",
       "35900                   \"My goal is to reach the people\"            n  \n",
       "35901  \"In general, I think that blanket policies on ...            n  \n",
       "35902                 \"Japanese ISPs To Ban FileSharers\"            n  \n",
       "35903   \"We should listen to the women and empower them\"            n  \n",
       "\n",
       "[35904 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12158 11591 12155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Over almost a decade since, the now 27 flouri...</td>\n",
       "      <td>\"She was right\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"{P5 A0} It becomes clear from other passages ...</td>\n",
       "      <td>\"North Koreans refugees are asylum seekers in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"As much as it pains me I'm going to agree wit...</td>\n",
       "      <td>\"NO I think that if certain religious groups c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Well, here is my take on it. I really believe...</td>\n",
       "      <td>\"I have never received an actual explanation f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"we have to help these tracers to get at least...</td>\n",
       "      <td>\"we should be doing more to control the virus\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35899</th>\n",
       "      <td>\"Она жертва.\"</td>\n",
       "      <td>\"Она виновна\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35900</th>\n",
       "      <td>\"And that doesn't make you wrong? But it only ...</td>\n",
       "      <td>\"but this is the point isn't it? You just knew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35901</th>\n",
       "      <td>\"good to know, I have been able to really use ...</td>\n",
       "      <td>\"netbooks are better than the ivagina\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35902</th>\n",
       "      <td>\"Lauren and Alice don’t know what each other’s...</td>\n",
       "      <td>\"it’s quite a thin slice\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35903</th>\n",
       "      <td>\"Mike D is a Canadian. What do you expect?\"</td>\n",
       "      <td>\"Mike D, you are indeed an idiot.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0      \"Over almost a decade since, the now 27 flouri...   \n",
       "1      \"{P5 A0} It becomes clear from other passages ...   \n",
       "2      \"As much as it pains me I'm going to agree wit...   \n",
       "3      \"Well, here is my take on it. I really believe...   \n",
       "4      \"we have to help these tracers to get at least...   \n",
       "...                                                  ...   \n",
       "35899                                      \"Она жертва.\"   \n",
       "35900  \"And that doesn't make you wrong? But it only ...   \n",
       "35901  \"good to know, I have been able to really use ...   \n",
       "35902  \"Lauren and Alice don’t know what each other’s...   \n",
       "35903        \"Mike D is a Canadian. What do you expect?\"   \n",
       "\n",
       "                                                       1  \n",
       "0                                        \"She was right\"  \n",
       "1      \"North Koreans refugees are asylum seekers in ...  \n",
       "2      \"NO I think that if certain religious groups c...  \n",
       "3      \"I have never received an actual explanation f...  \n",
       "4         \"we should be doing more to control the virus\"  \n",
       "...                                                  ...  \n",
       "35899                                      \"Она виновна\"  \n",
       "35900  \"but this is the point isn't it? You just knew...  \n",
       "35901             \"netbooks are better than the ivagina\"  \n",
       "35902                          \"it’s quite a thin slice\"  \n",
       "35903                 \"Mike D, you are indeed an idiot.\"  \n",
       "\n",
       "[35904 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35899</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35900</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35901</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35902</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35903</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35904 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      s\n",
       "1      n\n",
       "2      s\n",
       "3      s\n",
       "4      s\n",
       "...   ..\n",
       "35899  a\n",
       "35900  n\n",
       "35901  a\n",
       "35902  s\n",
       "35903  a\n",
       "\n",
       "[35904 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import dataset\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv(r\"training_data/AIFdb_Toni.csv\")\n",
    "display(df)\n",
    "df = shuffle(df).reset_index(drop=True)\n",
    "\n",
    "attack_count = df[df['relationship'] == \"a\"].count().iloc[0]\n",
    "support_count = df[df['relationship'] == \"s\"].count().iloc[0]\n",
    "neither_count = df[df['relationship'] == \"n\"].count().iloc[0]\n",
    "\n",
    "print(attack_count, support_count, neither_count)\n",
    "\n",
    "# Split features and labels\n",
    "X = df[[\"argument1\", \"argument2\"]].T.reset_index(drop=True).T\n",
    "y = df[[\"relationship\"]].T.reset_index(drop=True).T\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d686ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split pairs of sentences\n",
    "sentences_train_1 = X_train[0].to_numpy()\n",
    "sentences_train_2 = X_train[1].to_numpy()\n",
    "\n",
    "sentences_test_1 = X_test[0].to_numpy()\n",
    "sentences_test_2 = X_test[1].to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424b751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 ... 0 2 2]\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]] [[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# prepare target\n",
    "le = LabelEncoder()\n",
    "le.fit(np.ravel(y))\n",
    "y_train_enc = le.transform(np.ravel(y_train))\n",
    "y_test_enc = le.transform(np.ravel(y_test))\n",
    "print(y_test_enc)\n",
    "\n",
    "# one hot encoded\n",
    "y_train_enc = to_categorical(y_train_enc)\n",
    "y_test_enc = to_categorical(y_test_enc)\n",
    "\n",
    "print(y_train_enc, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f49c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten features for Glove fitting\n",
    "texts = np.concatenate([X[0], X[1]])\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "# Encode training data\n",
    "sequences_train_1 = tokenizer.texts_to_sequences(sentences_train_1)\n",
    "sequences_train_2 = tokenizer.texts_to_sequences(sentences_train_2)\n",
    "\n",
    "# Encode testing data\n",
    "sequences_test_1 = tokenizer.texts_to_sequences(sentences_test_1)\n",
    "sequences_test_2 = tokenizer.texts_to_sequences(sentences_test_2)\n",
    "\n",
    "# Padding sequences to have the same length\n",
    "max_len = 50\n",
    "print(max_len)\n",
    "\n",
    "padded_sequences_train_1 = pad_sequences(sequences_train_1, maxlen=max_len, padding='post')\n",
    "padded_sequences_train_2 = pad_sequences(sequences_train_2, maxlen=max_len, padding='post')\n",
    "\n",
    "padded_sequences_test_1 = pad_sequences(sequences_test_1, maxlen=max_len, padding='post')\n",
    "padded_sequences_test_2 = pad_sequences(sequences_test_2, maxlen=max_len, padding='post')\n",
    "\n",
    "#print(padded_sequences_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94e8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import numpy as np\n",
    "# Load pre-trained GloVe embeddings (you need to download the GloVe file)\n",
    "glove_embeddings_index = {}\n",
    "with open('glove/glove.6B.300d.txt', encoding='utf-8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix using GloVe for words in our tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eeb6549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_32 (Embedding)    (None, 50, 300)              1644120   ['input_33[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_33 (Embedding)    (None, 50, 300)              1644120   ['input_34[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_40 (LSTM)              (None, 50, 128)              219648    ['embedding_32[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_41 (LSTM)              (None, 50, 128)              219648    ['embedding_33[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)        (None, 50, 128)              0         ['lstm_40[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)        (None, 50, 128)              0         ['lstm_41[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenat  (None, 50, 256)              0         ['dropout_32[0][0]',          \n",
      " e)                                                                  'dropout_33[0][0]']          \n",
      "                                                                                                  \n",
      " global_max_pooling1d_9 (Gl  (None, 256)                  0         ['concatenate_16[0][0]']      \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 32)                   8224      ['global_max_pooling1d_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_33 (Dense)            (None, 3)                    99        ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33330019 (127.14 MB)\n",
      "Trainable params: 447619 (1.71 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create input layers\n",
    "#input_shape = (50, 100)\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "#lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = GlobalMaxPooling1D()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4e5e5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 37s 145ms/step - loss: 0.8868 - accuracy: 0.5937 - val_loss: 0.8181 - val_accuracy: 0.6599\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 29s 143ms/step - loss: 0.7712 - accuracy: 0.6697 - val_loss: 0.7672 - val_accuracy: 0.6707\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 31s 152ms/step - loss: 0.7045 - accuracy: 0.7004 - val_loss: 0.7312 - val_accuracy: 0.6892\n",
      "Epoch 4/50\n",
      " 23/202 [==>...........................] - ETA: 25s - loss: 0.6164 - accuracy: 0.7503"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      2\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpadded_sequences_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_sequences_train_2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.0001,\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786cae6-5650-4562-a713-4f140ccf3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate([padded_sequences_test_1, padded_sequences_test_2], y_test_enc, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_' + metric])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_' + metric])\n",
    "    plt.title('Training and Validation ' + metric.capitalize())\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'history' is the return value from model.fit()\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c6c9a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/IBM_model_full_300_better/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/IBM_model_full_300_better/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../saved_models/IBM_model_full_300_better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3493c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2314f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecd39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import numpy as np\n",
    "# Load pre-trained GloVe embeddings (you need to download the GloVe file)\n",
    "glove_embeddings_index = {}\n",
    "with open('glove/glove.6B.100d.txt', encoding='utf-8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix using GloVe for words in our tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5256626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 50, 100)              5480400   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 50, 100)              5480400   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 50, 32)               17024     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 50, 32)               17024     ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 50, 32)               0         ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 50, 32)               0         ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 50, 64)               0         ['dropout[0][0]',             \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 3200)                 0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 32)                   102432    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 3)                    99        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11097379 (42.33 MB)\n",
      "Trainable params: 11097379 (42.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=32, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=32, return_sequences=True)(emb2)\n",
    "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "#lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = Flatten()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "base_model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11142143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 38s 177ms/step - loss: 0.8622 - accuracy: 0.6132 - val_loss: 0.7681 - val_accuracy: 0.6634\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 39s 194ms/step - loss: 0.7033 - accuracy: 0.7053 - val_loss: 0.7179 - val_accuracy: 0.6906\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 37s 185ms/step - loss: 0.5813 - accuracy: 0.7601 - val_loss: 0.7364 - val_accuracy: 0.6871\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 34s 170ms/step - loss: 0.4605 - accuracy: 0.8161 - val_loss: 0.7689 - val_accuracy: 0.6989\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 34s 170ms/step - loss: 0.3454 - accuracy: 0.8647 - val_loss: 0.8504 - val_accuracy: 0.6930\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 33s 165ms/step - loss: 0.2486 - accuracy: 0.9064 - val_loss: 0.9455 - val_accuracy: 0.6940\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 33s 164ms/step - loss: 0.1763 - accuracy: 0.9360 - val_loss: 1.1570 - val_accuracy: 0.6853\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = base_model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4004a4cd-1712-4674-8208-c3273f90a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 2s 3ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      2447\n",
      "           1       0.73      0.61      0.66      2471\n",
      "           2       0.72      0.73      0.73      2264\n",
      "\n",
      "    accuracy                           0.70      7182\n",
      "   macro avg       0.70      0.70      0.70      7182\n",
      "weighted avg       0.70      0.70      0.70      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = base_model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc791740-b39b-4147-ae3a-892445fcf5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL WITH 300D GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b018542-0b63-4fbe-a3c0-62f0f18ccccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import numpy as np\n",
    "# Load pre-trained GloVe embeddings (you need to download the GloVe file)\n",
    "glove_embeddings_index = {}\n",
    "with open('glove/glove.6B.300d.txt', encoding='utf-8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix using GloVe for words in our tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e816cc05-9d32-4721-8f86-4af759b3c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 50, 300)              1644120   ['input_3[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 50, 300)              1644120   ['input_4[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 50, 32)               42624     ['embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 50, 32)               42624     ['embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 50, 32)               0         ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 50, 32)               0         ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 50, 64)               0         ['dropout_2[0][0]',           \n",
      " )                                                                   'dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 3200)                 0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   102432    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 3)                    99        ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33070179 (126.15 MB)\n",
      "Trainable params: 33070179 (126.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=32, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=32, return_sequences=True)(emb2)\n",
    "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "#lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = Flatten()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d050c05f-06df-4e51-8849-b1123d1ca19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 98s 471ms/step - loss: 0.8548 - accuracy: 0.6171 - val_loss: 0.7522 - val_accuracy: 0.6812\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 86s 424ms/step - loss: 0.6389 - accuracy: 0.7330 - val_loss: 0.7269 - val_accuracy: 0.6885\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 88s 434ms/step - loss: 0.4654 - accuracy: 0.8149 - val_loss: 0.7812 - val_accuracy: 0.6808\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 85s 419ms/step - loss: 0.3042 - accuracy: 0.8844 - val_loss: 0.9105 - val_accuracy: 0.6742\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 85s 422ms/step - loss: 0.1872 - accuracy: 0.9320 - val_loss: 1.1280 - val_accuracy: 0.6815\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49599b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 2s 4ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70      2447\n",
      "           1       0.72      0.59      0.65      2471\n",
      "           2       0.69      0.75      0.72      2264\n",
      "\n",
      "    accuracy                           0.69      7182\n",
      "   macro avg       0.69      0.69      0.69      7182\n",
      "weighted avg       0.69      0.69      0.69      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1b22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL WITH 300D GLOVE + 128D LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b08bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 50, 300)              1644120   ['input_5[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 50, 300)              1644120   ['input_6[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, 50, 128)              219648    ['embedding_4[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 50, 128)              219648    ['embedding_5[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 50, 128)              0         ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 50, 128)              0         ['lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 50, 256)              0         ['dropout_4[0][0]',           \n",
      " )                                                                   'dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 12800)                0         ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   409632    ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 3)                    99        ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33731427 (128.68 MB)\n",
      "Trainable params: 33731427 (128.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "#lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = Flatten()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b748baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 113s 546ms/step - loss: 0.8373 - accuracy: 0.6259 - val_loss: 0.7500 - val_accuracy: 0.6794\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 108s 536ms/step - loss: 0.6320 - accuracy: 0.7392 - val_loss: 0.6885 - val_accuracy: 0.7101\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 109s 540ms/step - loss: 0.4581 - accuracy: 0.8175 - val_loss: 0.7498 - val_accuracy: 0.7268\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 111s 552ms/step - loss: 0.2941 - accuracy: 0.8898 - val_loss: 0.8975 - val_accuracy: 0.6871\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 111s 549ms/step - loss: 0.1764 - accuracy: 0.9365 - val_loss: 1.0608 - val_accuracy: 0.6982\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 111s 549ms/step - loss: 0.1017 - accuracy: 0.9646 - val_loss: 1.2703 - val_accuracy: 0.6993\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "411149d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 5s 10ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73      2447\n",
      "           1       0.77      0.60      0.67      2471\n",
      "           2       0.73      0.73      0.73      2264\n",
      "\n",
      "    accuracy                           0.71      7182\n",
      "   macro avg       0.72      0.71      0.71      7182\n",
      "weighted avg       0.72      0.71      0.71      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac2c3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL + 300D GLOVE + 128D LSTM + 1DPOOLING & l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c4bd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 50, 300)              1644120   ['input_7[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, 50, 300)              1644120   ['input_8[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, 50, 128)              219648    ['embedding_6[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, 50, 128)              219648    ['embedding_7[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 50, 128)              0         ['lstm_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 50, 128)              0         ['lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 50, 256)              0         ['dropout_6[0][0]',           \n",
      " )                                                                   'dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 256)                  0         ['concatenate_3[0][0]']       \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 32)                   8224      ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 3)                    99        ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33330019 (127.14 MB)\n",
      "Trainable params: 447619 (1.71 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create input layers\n",
    "#input_shape = (50, 100)\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "#lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = GlobalMaxPooling1D()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b5bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 32s 147ms/step - loss: 1.0914 - accuracy: 0.5966 - val_loss: 0.9238 - val_accuracy: 0.6373\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 30s 148ms/step - loss: 0.8609 - accuracy: 0.6547 - val_loss: 0.8808 - val_accuracy: 0.6189\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 32s 156ms/step - loss: 0.8089 - accuracy: 0.6739 - val_loss: 0.8147 - val_accuracy: 0.6833\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 30s 148ms/step - loss: 0.7622 - accuracy: 0.6961 - val_loss: 0.8042 - val_accuracy: 0.6853\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 28s 136ms/step - loss: 0.7244 - accuracy: 0.7197 - val_loss: 0.7664 - val_accuracy: 0.7115\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 27s 133ms/step - loss: 0.6978 - accuracy: 0.7302 - val_loss: 0.7504 - val_accuracy: 0.7156\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 26s 131ms/step - loss: 0.6473 - accuracy: 0.7563 - val_loss: 0.7545 - val_accuracy: 0.7080\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 26s 130ms/step - loss: 0.6191 - accuracy: 0.7696 - val_loss: 0.7394 - val_accuracy: 0.7205\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 26s 131ms/step - loss: 0.5790 - accuracy: 0.7891 - val_loss: 0.7231 - val_accuracy: 0.7229\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 27s 131ms/step - loss: 0.5477 - accuracy: 0.7997 - val_loss: 0.7236 - val_accuracy: 0.7160\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 26s 131ms/step - loss: 0.5166 - accuracy: 0.8164 - val_loss: 0.7352 - val_accuracy: 0.7250\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 26s 131ms/step - loss: 0.4764 - accuracy: 0.8383 - val_loss: 0.7290 - val_accuracy: 0.7215\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 29s 145ms/step - loss: 0.4384 - accuracy: 0.8541 - val_loss: 0.7422 - val_accuracy: 0.7296\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 26s 130ms/step - loss: 0.4160 - accuracy: 0.8639 - val_loss: 0.7644 - val_accuracy: 0.7212\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 29s 142ms/step - loss: 0.3739 - accuracy: 0.8814 - val_loss: 0.7751 - val_accuracy: 0.7222\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 27s 135ms/step - loss: 0.3409 - accuracy: 0.8959 - val_loss: 0.8052 - val_accuracy: 0.7177\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c178e866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 6s 12ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.74      2447\n",
      "           1       0.81      0.61      0.69      2471\n",
      "           2       0.72      0.75      0.74      2264\n",
      "\n",
      "    accuracy                           0.72      7182\n",
      "   macro avg       0.73      0.72      0.72      7182\n",
      "weighted avg       0.73      0.72      0.72      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a97a0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL + 300D GLOVE + 128D BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "959df338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)     (None, 50, 300)              1644120   ['input_9[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, 50, 300)              1644120   ['input_10[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 50, 256)              439296    ['embedding_8[0][0]']         \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 50, 256)              439296    ['embedding_9[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 50, 256)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 50, 256)              0         ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 50, 512)              0         ['dropout_8[0][0]',           \n",
      " )                                                                   'dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 25600)                0         ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 32)                   819232    ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 3)                    99        ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34580323 (131.91 MB)\n",
      "Trainable params: 34580323 (131.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "#lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "#lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = Flatten()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13eed956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 147s 702ms/step - loss: 0.8457 - accuracy: 0.6226 - val_loss: 0.7636 - val_accuracy: 0.6645\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 145s 716ms/step - loss: 0.6142 - accuracy: 0.7477 - val_loss: 0.7152 - val_accuracy: 0.7038\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 143s 709ms/step - loss: 0.4145 - accuracy: 0.8398 - val_loss: 0.7965 - val_accuracy: 0.6937\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 144s 711ms/step - loss: 0.2573 - accuracy: 0.9043 - val_loss: 0.9487 - val_accuracy: 0.6982\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 144s 711ms/step - loss: 0.1520 - accuracy: 0.9462 - val_loss: 1.1547 - val_accuracy: 0.6989\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878b8798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 9s 18ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      2447\n",
      "           1       0.71      0.60      0.65      2471\n",
      "           2       0.68      0.75      0.72      2264\n",
      "\n",
      "    accuracy                           0.69      7182\n",
      "   macro avg       0.69      0.69      0.69      7182\n",
      "weighted avg       0.69      0.69      0.69      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b83af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL + 300D GLOVE + 128D LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c8479d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)    (None, 50, 300)              1644120   ['input_11[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)    (None, 50, 300)              1644120   ['input_12[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, 50, 128)              219648    ['embedding_10[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, 50, 128)              219648    ['embedding_11[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 50, 128)              0         ['lstm_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 50, 128)              0         ['lstm_11[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 50, 256)              0         ['dropout_10[0][0]',          \n",
      " )                                                                   'dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 12800)                0         ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 32)                   409632    ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 3)                    99        ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33731427 (128.68 MB)\n",
      "Trainable params: 849027 (3.24 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "#lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = Flatten()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c07079c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 31s 143ms/step - loss: 0.8666 - accuracy: 0.6115 - val_loss: 0.7886 - val_accuracy: 0.6565\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 29s 145ms/step - loss: 0.7327 - accuracy: 0.6895 - val_loss: 0.7522 - val_accuracy: 0.6773\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 29s 141ms/step - loss: 0.6436 - accuracy: 0.7335 - val_loss: 0.7044 - val_accuracy: 0.7090\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 28s 138ms/step - loss: 0.5550 - accuracy: 0.7717 - val_loss: 0.7762 - val_accuracy: 0.6836\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 28s 139ms/step - loss: 0.4683 - accuracy: 0.8141 - val_loss: 0.7297 - val_accuracy: 0.7066\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 30s 149ms/step - loss: 0.3780 - accuracy: 0.8526 - val_loss: 0.8012 - val_accuracy: 0.6968\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fd01855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 5s 10ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70      2447\n",
      "           1       0.72      0.64      0.68      2471\n",
      "           2       0.74      0.70      0.72      2264\n",
      "\n",
      "    accuracy                           0.70      7182\n",
      "   macro avg       0.70      0.70      0.70      7182\n",
      "weighted avg       0.70      0.70      0.70      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86f345cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention upgraded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdf24672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)    (None, 50, 300)              1644120   ['input_13[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_13 (Embedding)    (None, 50, 300)              1644120   ['input_14[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)              (None, 50, 128)              219648    ['embedding_12[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)              (None, 50, 128)              219648    ['embedding_13[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 50, 128)              0         ['lstm_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 50, 128)              0         ['lstm_13[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 50, 256)              0         ['dropout_12[0][0]',          \n",
      " )                                                                   'dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 12800)                0         ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 32)                   409632    ['flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 3)                    99        ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33731427 (128.68 MB)\n",
      "Trainable params: 849027 (3.24 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "\n",
    "# Dropouts\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the attended outputs\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "flat = Flatten()(concatenated)\n",
    "\n",
    "# Instead of flattening, feed the concatenated attended outputs directly to the dense layer\n",
    "dense_layer = Dense(32, activation='relu')(flat)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "680239e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 37s 161ms/step - loss: 0.8977 - accuracy: 0.5789 - val_loss: 0.7932 - val_accuracy: 0.6509\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 31s 153ms/step - loss: 0.7686 - accuracy: 0.6662 - val_loss: 0.7671 - val_accuracy: 0.6634\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 31s 154ms/step - loss: 0.6748 - accuracy: 0.7125 - val_loss: 0.7204 - val_accuracy: 0.6954\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 31s 154ms/step - loss: 0.5864 - accuracy: 0.7571 - val_loss: 0.7218 - val_accuracy: 0.7125\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 31s 152ms/step - loss: 0.5062 - accuracy: 0.7945 - val_loss: 0.7294 - val_accuracy: 0.7128\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 31s 152ms/step - loss: 0.4296 - accuracy: 0.8299 - val_loss: 0.7804 - val_accuracy: 0.7163\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 31s 152ms/step - loss: 0.3620 - accuracy: 0.8578 - val_loss: 0.8183 - val_accuracy: 0.7146\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 31s 152ms/step - loss: 0.2927 - accuracy: 0.8884 - val_loss: 0.9328 - val_accuracy: 0.7160\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 31s 153ms/step - loss: 0.2260 - accuracy: 0.9171 - val_loss: 0.9849 - val_accuracy: 0.7128\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "359ea4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 7s 11ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73      2447\n",
      "           1       0.74      0.63      0.68      2471\n",
      "           2       0.74      0.71      0.72      2264\n",
      "\n",
      "    accuracy                           0.71      7182\n",
      "   macro avg       0.72      0.71      0.71      7182\n",
      "weighted avg       0.71      0.71      0.71      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "632d2a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_' + metric])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_' + metric])\n",
    "    plt.title('Training and Validation ' + metric.capitalize())\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'history' is the return value from model.fit()\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1e5cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3b89633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_14 (Embedding)    (None, 50, 300)              1644120   ['input_15[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)    (None, 50, 300)              1644120   ['input_16[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 50, 256)              439296    ['embedding_14[0][0]']        \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, 50, 256)              439296    ['embedding_15[0][0]']        \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 50, 256)              0         ['bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 50, 256)              0         ['bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 50, 512)              0         ['dropout_14[0][0]',          \n",
      " )                                                                   'dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 25600)                0         ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 32)                   819232    ['flatten_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 3)                    99        ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34580323 (131.91 MB)\n",
      "Trainable params: 1697923 (6.48 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "# Dropouts\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Concatenate the attended outputs\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "flat = Flatten()(concatenated)\n",
    "\n",
    "# Instead of flattening, feed the concatenated attended outputs directly to the dense layer\n",
    "dense_layer = Dense(32, activation='relu')(flat)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "456cb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 77s 337ms/step - loss: 0.8827 - accuracy: 0.6045 - val_loss: 0.7963 - val_accuracy: 0.6551\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 64s 318ms/step - loss: 0.7255 - accuracy: 0.6918 - val_loss: 0.7561 - val_accuracy: 0.6857\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 65s 320ms/step - loss: 0.6255 - accuracy: 0.7410 - val_loss: 0.7582 - val_accuracy: 0.6961\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 65s 323ms/step - loss: 0.5254 - accuracy: 0.7889 - val_loss: 0.7989 - val_accuracy: 0.6829\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 64s 319ms/step - loss: 0.4176 - accuracy: 0.8384 - val_loss: 0.8118 - val_accuracy: 0.6916\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 75s 371ms/step - loss: 0.3163 - accuracy: 0.8810 - val_loss: 0.9354 - val_accuracy: 0.6718\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95973c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 15s 23ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70      2447\n",
      "           1       0.72      0.58      0.64      2471\n",
      "           2       0.75      0.69      0.72      2264\n",
      "\n",
      "    accuracy                           0.69      7182\n",
      "   macro avg       0.70      0.69      0.69      7182\n",
      "weighted avg       0.70      0.69      0.68      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67775bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL + 300D GLOVE + 256D BiLSTM + attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96bde5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_24 (Embedding)    (None, 50, 300)              1644120   ['input_25[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_25 (Embedding)    (None, 50, 300)              1644120   ['input_26[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " bidirectional_10 (Bidirect  (None, 50, 512)              1140736   ['embedding_24[0][0]']        \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional_11 (Bidirect  (None, 50, 512)              1140736   ['embedding_25[0][0]']        \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)        (None, 50, 512)              0         ['bidirectional_10[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 50, 512)              0         ['bidirectional_11[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 50, 1024)             0         ['dropout_24[0][0]',          \n",
      " e)                                                                  'dropout_25[0][0]']          \n",
      "                                                                                                  \n",
      " global_max_pooling1d_5 (Gl  (None, 1024)                 0         ['concatenate_12[0][0]']      \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 32)                   32800     ['global_max_pooling1d_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 3)                    99        ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35196771 (134.27 MB)\n",
      "Trainable params: 2314371 (8.83 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "#lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "#lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "lstm1 = Bidirectional(LSTM(units=256, return_sequences=True))(emb1)\n",
    "lstm2 = Bidirectional(LSTM(units=256, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.5)(lstm1)\n",
    "dropout2 = Dropout(0.5)(lstm2)\n",
    "\n",
    "# Concatenate the outputs of both LSTM layers\n",
    "concatenated = concatenate([dropout1, dropout2], axis=-1)\n",
    "\n",
    "# Reduce dimensionality while preserving important features\n",
    "pooled = GlobalMaxPooling1D()(concatenated)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80dded65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 172s 801ms/step - loss: 0.8682 - accuracy: 0.6091 - val_loss: 0.8226 - val_accuracy: 0.6718\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 150s 741ms/step - loss: 0.7317 - accuracy: 0.6975 - val_loss: 0.7761 - val_accuracy: 0.7038\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 152s 754ms/step - loss: 0.6539 - accuracy: 0.7322 - val_loss: 0.7321 - val_accuracy: 0.7167\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 148s 732ms/step - loss: 0.5894 - accuracy: 0.7605 - val_loss: 0.6875 - val_accuracy: 0.7299\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 150s 740ms/step - loss: 0.5195 - accuracy: 0.7906 - val_loss: 0.6825 - val_accuracy: 0.7309\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 149s 739ms/step - loss: 0.4539 - accuracy: 0.8182 - val_loss: 0.6845 - val_accuracy: 0.7156\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 152s 754ms/step - loss: 0.3899 - accuracy: 0.8505 - val_loss: 0.6653 - val_accuracy: 0.7289\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 157s 779ms/step - loss: 0.3224 - accuracy: 0.8776 - val_loss: 0.6634 - val_accuracy: 0.7271\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67670a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 19s 33ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73      2447\n",
      "           1       0.84      0.55      0.66      2471\n",
      "           2       0.72      0.75      0.73      2264\n",
      "\n",
      "    accuracy                           0.71      7182\n",
      "   macro avg       0.74      0.72      0.71      7182\n",
      "weighted avg       0.74      0.71      0.71      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4819e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention P to C with 2 LSTM 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e024377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_27 (Embedding)    (None, 50, 300)              1644120   ['input_28[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)    (None, 50, 300)              1644120   ['input_27[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_29 (LSTM)              (None, 50, 64)               93440     ['embedding_27[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_28 (LSTM)              (None, 50, 64)               93440     ['embedding_26[0][0]']        \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                 (None, 50, 50)               0         ['lstm_29[0][0]',             \n",
      "                                                                     'lstm_28[0][0]']             \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                 (None, 50, 50)               0         ['lstm_28[0][0]',             \n",
      "                                                                     'lstm_29[0][0]']             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 50, 50)               0         ['dot_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 50, 50)               0         ['dot_6[0][0]']               \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                 (None, 50, 64)               0         ['activation_2[0][0]',        \n",
      "                                                                     'lstm_29[0][0]']             \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                 (None, 50, 64)               0         ['activation_3[0][0]',        \n",
      "                                                                     'lstm_28[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_30 (LSTM)              (None, 50, 64)               33024     ['dot_5[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_31 (LSTM)              (None, 50, 64)               33024     ['dot_7[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenat  (None, 50, 128)              0         ['lstm_30[0][0]',             \n",
      " e)                                                                  'lstm_31[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_6 (Gl  (None, 128)                  0         ['concatenate_13[0][0]']      \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 32)                   4128      ['global_max_pooling1d_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 3)                    99        ['dense_26[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33139555 (126.42 MB)\n",
      "Trainable params: 257155 (1004.51 KB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, concatenate, Permute, Reshape, Dot, Activation, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the P to C attention mechanism\n",
    "def p_to_c_attention(child, parent):\n",
    "    # Step 1: Dot product between parent and child sequences to get the attention scores\n",
    "    attention_scores = Dot(axes=[2, 2])([parent, child])\n",
    "    \n",
    "    # Step 2: Apply softmax to get attention distribution\n",
    "    attention_distribution = Activation('softmax')(attention_scores)\n",
    "    \n",
    "    # Step 3: Use the attention distribution to compute weighted sum of parent sequences\n",
    "    weighted_sum = Dot(axes=[1, 1])([attention_distribution, parent])\n",
    "    \n",
    "    return weighted_sum\n",
    "\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=64, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=64, return_sequences=True)(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Apply P to C attention\n",
    "p_to_c_attended = p_to_c_attention(lstm1, lstm2)\n",
    "c_to_p_attended = p_to_c_attention(lstm2, lstm1)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm3 = LSTM(units=64, return_sequences=True)(p_to_c_attended)\n",
    "lstm4 = LSTM(units=64, return_sequences=True)(c_to_p_attended)\n",
    "\n",
    "# Optionally combine attended output with the original child sequence\n",
    "combined_sequence = concatenate([lstm3, lstm4])\n",
    "\n",
    "# Continue with model construction\n",
    "pooled = GlobalMaxPooling1D()(combined_sequence)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dee4f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.8919 - accuracy: 0.5924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1711738478.048241       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1711738478.048313       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 37s 144ms/step - loss: 0.8919 - accuracy: 0.5924 - val_loss: 0.8065 - val_accuracy: 0.6578\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 27s 131ms/step - loss: 0.7680 - accuracy: 0.6771 - val_loss: 0.7603 - val_accuracy: 0.6780\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 26s 130ms/step - loss: 0.7132 - accuracy: 0.7004 - val_loss: 0.7350 - val_accuracy: 0.6951\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 31s 151ms/step - loss: 0.6352 - accuracy: 0.7425 - val_loss: 0.7019 - val_accuracy: 0.7076\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 24s 121ms/step - loss: 0.5629 - accuracy: 0.7785 - val_loss: 0.6736 - val_accuracy: 0.7369\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 24s 119ms/step - loss: 0.4922 - accuracy: 0.8080 - val_loss: 0.6821 - val_accuracy: 0.7344\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 24s 121ms/step - loss: 0.4315 - accuracy: 0.8353 - val_loss: 0.6911 - val_accuracy: 0.7410\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 25s 124ms/step - loss: 0.3671 - accuracy: 0.8617 - val_loss: 0.7635 - val_accuracy: 0.7417\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 26s 131ms/step - loss: 0.3216 - accuracy: 0.8812 - val_loss: 0.8164 - val_accuracy: 0.7299\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 27s 131ms/step - loss: 0.2734 - accuracy: 0.9001 - val_loss: 0.8776 - val_accuracy: 0.7351\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7876831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1711738716.070178       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1711738716.070241       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 6s 9ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74      2447\n",
      "           1       0.78      0.67      0.72      2471\n",
      "           2       0.77      0.72      0.74      2264\n",
      "\n",
      "    accuracy                           0.73      7182\n",
      "   macro avg       0.74      0.73      0.73      7182\n",
      "weighted avg       0.74      0.73      0.73      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7c5ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention P to C with 2 LSTM 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39e800ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_30 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)       [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_29 (Embedding)    (None, 50, 300)              1644120   ['input_30[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_28 (Embedding)    (None, 50, 300)              1644120   ['input_29[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)              (None, 50, 128)              219648    ['embedding_29[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_32 (LSTM)              (None, 50, 128)              219648    ['embedding_28[0][0]']        \n",
      "                                                                                                  \n",
      " dot_8 (Dot)                 (None, 50, 50)               0         ['lstm_33[0][0]',             \n",
      "                                                                     'lstm_32[0][0]']             \n",
      "                                                                                                  \n",
      " dot_10 (Dot)                (None, 50, 50)               0         ['lstm_32[0][0]',             \n",
      "                                                                     'lstm_33[0][0]']             \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 50, 50)               0         ['dot_8[0][0]']               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 50, 50)               0         ['dot_10[0][0]']              \n",
      "                                                                                                  \n",
      " dot_9 (Dot)                 (None, 50, 128)              0         ['activation_4[0][0]',        \n",
      "                                                                     'lstm_33[0][0]']             \n",
      "                                                                                                  \n",
      " dot_11 (Dot)                (None, 50, 128)              0         ['activation_5[0][0]',        \n",
      "                                                                     'lstm_32[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_34 (LSTM)              (None, 50, 128)              131584    ['dot_9[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_35 (LSTM)              (None, 50, 128)              131584    ['dot_11[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenat  (None, 50, 256)              0         ['lstm_34[0][0]',             \n",
      " e)                                                                  'lstm_35[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_7 (Gl  (None, 256)                  0         ['concatenate_14[0][0]']      \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 32)                   8224      ['global_max_pooling1d_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 3)                    99        ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33593187 (128.15 MB)\n",
      "Trainable params: 710787 (2.71 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, concatenate, Permute, Reshape, Dot, Activation, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the P to C attention mechanism\n",
    "def p_to_c_attention(child, parent):\n",
    "    # Step 1: Dot product between parent and child sequences to get the attention scores\n",
    "    attention_scores = Dot(axes=[2, 2])([parent, child])\n",
    "    \n",
    "    # Step 2: Apply softmax to get attention distribution\n",
    "    attention_distribution = Activation('softmax')(attention_scores)\n",
    "    \n",
    "    # Step 3: Use the attention distribution to compute weighted sum of parent sequences\n",
    "    weighted_sum = Dot(axes=[1, 1])([attention_distribution, parent])\n",
    "    \n",
    "    return weighted_sum\n",
    "\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = LSTM(units=128, return_sequences=True)(emb1)\n",
    "lstm2 = LSTM(units=128, return_sequences=True)(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Apply P to C attention\n",
    "p_to_c_attended = p_to_c_attention(lstm1, lstm2)\n",
    "c_to_p_attended = p_to_c_attention(lstm2, lstm1)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm3 = LSTM(units=128, return_sequences=True)(p_to_c_attended)\n",
    "lstm4 = LSTM(units=128, return_sequences=True)(c_to_p_attended)\n",
    "\n",
    "# Optionally combine attended output with the original child sequence\n",
    "combined_sequence = concatenate([lstm3, lstm4])\n",
    "\n",
    "# Continue with model construction\n",
    "pooled = GlobalMaxPooling1D()(combined_sequence)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9706292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.6071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1711738795.839662       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1711738795.839711       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 76s 339ms/step - loss: 0.8690 - accuracy: 0.6071 - val_loss: 0.7857 - val_accuracy: 0.6610\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 67s 329ms/step - loss: 0.7486 - accuracy: 0.6821 - val_loss: 0.7369 - val_accuracy: 0.6934\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 67s 329ms/step - loss: 0.6834 - accuracy: 0.7182 - val_loss: 0.7122 - val_accuracy: 0.6996\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 67s 334ms/step - loss: 0.6170 - accuracy: 0.7516 - val_loss: 0.6773 - val_accuracy: 0.7226\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 68s 337ms/step - loss: 0.5409 - accuracy: 0.7856 - val_loss: 0.6906 - val_accuracy: 0.7271\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 67s 334ms/step - loss: 0.4744 - accuracy: 0.8131 - val_loss: 0.6951 - val_accuracy: 0.7355\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 67s 332ms/step - loss: 0.4031 - accuracy: 0.8414 - val_loss: 0.7070 - val_accuracy: 0.7470\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 67s 333ms/step - loss: 0.3475 - accuracy: 0.8658 - val_loss: 0.7582 - val_accuracy: 0.7341\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 67s 334ms/step - loss: 0.2925 - accuracy: 0.8882 - val_loss: 0.9054 - val_accuracy: 0.7313\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 66s 327ms/step - loss: 0.2455 - accuracy: 0.9066 - val_loss: 0.9434 - val_accuracy: 0.7362\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d23a0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1711739405.092297       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1711739405.092348       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 10s 17ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73      2447\n",
      "           1       0.78      0.66      0.72      2471\n",
      "           2       0.76      0.73      0.74      2264\n",
      "\n",
      "    accuracy                           0.73      7182\n",
      "   macro avg       0.74      0.73      0.73      7182\n",
      "weighted avg       0.74      0.73      0.73      7182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb12ffb-0a5a-47a1-ab1b-cfbf58603faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 50, 300)              1644120   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 50, 300)              1644120   ['input_1[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 50, 256)              439296    ['embedding_1[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 50, 256)              439296    ['embedding[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 50, 256)              0         ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 50, 256)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 50, 50)               0         ['dropout_1[0][0]',           \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                 (None, 50, 50)               0         ['dropout[0][0]',             \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 50, 50)               0         ['dot[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 50, 50)               0         ['dot_2[0][0]']               \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                 (None, 50, 256)              0         ['activation[0][0]',          \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                 (None, 50, 256)              0         ['activation_1[0][0]',        \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 50, 256)              394240    ['dot_1[0][0]']               \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, 50, 256)              394240    ['dot_3[0][0]']               \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 50, 512)              0         ['bidirectional_2[0][0]',     \n",
      "                                                                     'bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 512)                  0         ['concatenate[0][0]']         \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 32)                   16416     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 3)                    99        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34565987 (131.86 MB)\n",
      "Trainable params: 1683587 (6.42 MB)\n",
      "Non-trainable params: 32882400 (125.44 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, concatenate, Permute, Reshape, Dot, Activation, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the P to C attention mechanism\n",
    "def p_to_c_attention(child, parent):\n",
    "    # Step 1: Dot product between parent and child sequences to get the attention scores\n",
    "    attention_scores = Dot(axes=[2, 2])([parent, child])\n",
    "    \n",
    "    # Step 2: Apply softmax to get attention distribution\n",
    "    attention_distribution = Activation('softmax')(attention_scores)\n",
    "    \n",
    "    # Step 3: Use the attention distribution to compute weighted sum of parent sequences\n",
    "    weighted_sum = Dot(axes=[1, 1])([attention_distribution, parent])\n",
    "    \n",
    "    return weighted_sum\n",
    "\n",
    "input_shape = (max_len,)\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Create Embedding layer\n",
    "emb1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input1)\n",
    "emb2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False, mask_zero=True)(input2)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm1 = Bidirectional(LSTM(units=128, return_sequences=True))(emb1)\n",
    "lstm2 = Bidirectional(LSTM(units=128, return_sequences=True))(emb2)\n",
    "\n",
    "dropout1 = Dropout(0.2)(lstm1)\n",
    "dropout2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Apply P to C attention\n",
    "p_to_c_attended = p_to_c_attention(dropout1, dropout2)\n",
    "c_to_p_attended = p_to_c_attention(dropout2, dropout1)\n",
    "\n",
    "# Create LSTM layers\n",
    "lstm3 = Bidirectional(LSTM(units=128, return_sequences=True))(p_to_c_attended)\n",
    "lstm4 = Bidirectional(LSTM(units=128, return_sequences=True))(c_to_p_attended)\n",
    "\n",
    "# Optionally combine attended output with the original child sequence\n",
    "combined_sequence = concatenate([lstm3, lstm4])\n",
    "\n",
    "# Continue with model construction\n",
    "pooled = GlobalMaxPooling1D()(combined_sequence)\n",
    "\n",
    "# Add a Dense layer for further processing\n",
    "dense_layer = Dense(32, activation='relu')(pooled)\n",
    "\n",
    "# Add an output layer\n",
    "output = Dense(3, activation='softmax')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af14a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.8895 - accuracy: 0.5926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1712688209.976257       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1712688209.976388       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 157s 710ms/step - loss: 0.8895 - accuracy: 0.5926 - val_loss: 0.8273 - val_accuracy: 0.6432\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 142s 703ms/step - loss: 0.7873 - accuracy: 0.6591 - val_loss: 0.7788 - val_accuracy: 0.6578\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 141s 696ms/step - loss: 0.7165 - accuracy: 0.6994 - val_loss: 0.7192 - val_accuracy: 0.7000\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 145s 716ms/step - loss: 0.6563 - accuracy: 0.7317 - val_loss: 0.6834 - val_accuracy: 0.7174\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 141s 698ms/step - loss: 0.5960 - accuracy: 0.7616 - val_loss: 0.6758 - val_accuracy: 0.7236\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 139s 689ms/step - loss: 0.5366 - accuracy: 0.7852 - val_loss: 0.7085 - val_accuracy: 0.7125\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 150s 741ms/step - loss: 0.4819 - accuracy: 0.8126 - val_loss: 0.6957 - val_accuracy: 0.7261\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 154s 762ms/step - loss: 0.4254 - accuracy: 0.8343 - val_loss: 0.7399 - val_accuracy: 0.7316\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 162s 804ms/step - loss: 0.3626 - accuracy: 0.8615 - val_loss: 0.7668 - val_accuracy: 0.7344\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 161s 795ms/step - loss: 0.2992 - accuracy: 0.8863 - val_loss: 0.8377 - val_accuracy: 0.7257\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 154s 758ms/step - loss: 0.2617 - accuracy: 0.9019 - val_loss: 0.8851 - val_accuracy: 0.7341\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 150s 745ms/step - loss: 0.2102 - accuracy: 0.9226 - val_loss: 0.9455 - val_accuracy: 0.7243\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [padded_sequences_train_1, padded_sequences_train_2], \n",
    "    y=y_train_enc, \n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb63401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1712689858.371087       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1712689858.371186       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 19s 32ms/step\n",
      "{'a': 0, 'n': 1, 's': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.73      2424\n",
      "           1       0.81      0.62      0.70      2461\n",
      "           2       0.74      0.78      0.76      2296\n",
      "\n",
      "    accuracy                           0.73      7181\n",
      "   macro avg       0.74      0.73      0.73      7181\n",
      "weighted avg       0.74      0.73      0.73      7181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict([padded_sequences_test_1, padded_sequences_test_2], batch_size=16, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "print(classification_report(np.argmax(y_test_enc,axis=1), y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1880880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e523e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149215cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cce82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da59a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
